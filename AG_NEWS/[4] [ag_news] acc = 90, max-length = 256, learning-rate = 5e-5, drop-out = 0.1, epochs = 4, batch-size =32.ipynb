{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[yahoo]ep 4, batch64, ml256,  lr2e-5, dropout01, acc92 .ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2764bafc96e0422290d61a22f39c5120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f08d012767c4e5db7ea8f777d208dd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c92adb33225f4dfb97b9cc1d5039cf43",
              "IPY_MODEL_39144536ccec45e6aa23886e02c34733"
            ]
          }
        },
        "0f08d012767c4e5db7ea8f777d208dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c92adb33225f4dfb97b9cc1d5039cf43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95664e5d5c7c4b3fb544ea54b894d6c8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bd87d2f433d421484011bcdb20ec04c"
          }
        },
        "39144536ccec45e6aa23886e02c34733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e9e9b61ffbf4b87923d47758f5badbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 726kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5805e0c7b7264938b5e673ed6837d00f"
          }
        },
        "95664e5d5c7c4b3fb544ea54b894d6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bd87d2f433d421484011bcdb20ec04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e9e9b61ffbf4b87923d47758f5badbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5805e0c7b7264938b5e673ed6837d00f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6618cb74c4184d57a5eb610b88bc2d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca03779df9f640e19b0bef5dcb9539b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_296c4190bd8d47fa94c0691fbd9e35b3",
              "IPY_MODEL_745d55b6119a477a9c8f3a5f8cd31e17"
            ]
          }
        },
        "ca03779df9f640e19b0bef5dcb9539b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "296c4190bd8d47fa94c0691fbd9e35b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dce9d658cb9e42cda8a1b03f327085ca",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec555c6b092d47e08bf1a7591db9c440"
          }
        },
        "745d55b6119a477a9c8f3a5f8cd31e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f39d682e1b22451889d737b4d12943e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 155B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_766efdbd7ea042778ebed40a5c77c848"
          }
        },
        "dce9d658cb9e42cda8a1b03f327085ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec555c6b092d47e08bf1a7591db9c440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f39d682e1b22451889d737b4d12943e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "766efdbd7ea042778ebed40a5c77c848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "529140a8709f416c8962a8758f71ba46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd012ba9bed4423d8c03a66b66423130",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_925af190d30c4dae9826ffdb7718e611",
              "IPY_MODEL_2d15821345a04b469075116ab1b06ddb"
            ]
          }
        },
        "bd012ba9bed4423d8c03a66b66423130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "925af190d30c4dae9826ffdb7718e611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76980fa5c7914fad8c936240b2e7f3cd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6a93efd878b40759599f74ddc075de8"
          }
        },
        "2d15821345a04b469075116ab1b06ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c5dbcf4e9bb64101bc1f08da6936c1b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 4.74MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6466d76c3464bce8bdc099750e897b6"
          }
        },
        "76980fa5c7914fad8c936240b2e7f3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6a93efd878b40759599f74ddc075de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5dbcf4e9bb64101bc1f08da6936c1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6466d76c3464bce8bdc099750e897b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c98fc1dce344fad80e4525ffbfb48c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73732e79f03b45a284f3762cfc86ab15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_142ee2f5b5c44dc3b3426b0ff5704f80",
              "IPY_MODEL_5a96f1c483fb4d0794ac608af7cd99a6"
            ]
          }
        },
        "73732e79f03b45a284f3762cfc86ab15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "142ee2f5b5c44dc3b3426b0ff5704f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfa8ba12162740039c86d82982d049a6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ef847a3d25840efafeb6ac461c6deab"
          }
        },
        "5a96f1c483fb4d0794ac608af7cd99a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_309f72869d5845948cd180f3f27a739e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:09&lt;00:00, 57.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ff523e2b6c94edc8b03b63986a00369"
          }
        },
        "cfa8ba12162740039c86d82982d049a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ef847a3d25840efafeb6ac461c6deab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "309f72869d5845948cd180f3f27a739e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ff523e2b6c94edc8b03b63986a00369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae9d9b1c158d4b0784dbcfb341592682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffa55e37819547bd83576240f5e6ebf4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f5a9a1de869c4946b04aa8ceb333b880",
              "IPY_MODEL_4e949fbfa24f4b4b962b48bfe29e3ce9"
            ]
          }
        },
        "ffa55e37819547bd83576240f5e6ebf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5a9a1de869c4946b04aa8ceb333b880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf31f9ada3514672916ab5ccb377de0c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6097930e573b4ee1ae99f45587a901c2"
          }
        },
        "4e949fbfa24f4b4b962b48bfe29e3ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_457f701a1c414b48bdc8f730339331b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 46.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_166d27764fe54402babbd8100653af75"
          }
        },
        "bf31f9ada3514672916ab5ccb377de0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6097930e573b4ee1ae99f45587a901c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "457f701a1c414b48bdc8f730339331b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "166d27764fe54402babbd8100653af75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JWNLP/classification/blob/main/%5B4%5D%20%5Bag_news%5D%20acc%20%3D%2090%2C%20max-length%20%3D%20256%2C%20learning-rate%20%3D%205e-5%2C%20drop-out%20%3D%200.1%2C%20epochs%20%3D%204%2C%20batch-size%20%3D32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODT5aounmWtT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIwXBwf2l9Hh"
      },
      "source": [
        "## ag_news_csv\n",
        "\n",
        "> \n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ag_news_csv/ag_news_csv/train.csv\", delimiter=',', header=None, names=['label', 'sentence'])\n",
        "\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/ag_news_csv/ag_news_csv/test.csv\", delimiter=',', header=None, names=['label', 'sentence'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ1AiW4am5G0",
        "outputId": "46ac44c8-366d-4ed7-f2e4-e18d0f0af6f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbmwCmOsX36p",
        "outputId": "107eb745-d1ad-4306-e62f-0b926ab32a69"
      },
      "source": [
        "pip install transformers\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 35.0MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hzzzfMlec-"
      },
      "source": [
        "pip install pyspark\n",
        "\n",
        "\n",
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUW-7Uu-23le",
        "outputId": "f76fc61a-5379-4fce-e18a-c12fa590ba07"
      },
      "source": [
        "pip install matplotlib"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKXLb7Ot-ogN",
        "outputId": "43293c24-3971-4f6e-9993-2c6bc3aaadc0"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVfzNcrBYfAc"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from tqdm import tqdm\n",
        "\n",
        "import argparse\n",
        "import easydict\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpP4TmL_3f5Y"
      },
      "source": [
        "DATA_TRAIN_PATH = \"/content/drive/MyDrive/ag_news_csv/ag_news_csv/train.csv\"\n",
        "DATA_TEST_PATH = \"/content/drive/MyDrive/ag_news_csv/ag_news_csv/test.csv\"\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "q8Uh09hz4vcw",
        "outputId": "86bbb861-a1bc-4428-f17e-aef86cdb0afb"
      },
      "source": [
        "\"\"\"\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-seed', default=0, type=int)\n",
        "parser.add_argument('-max_seq_length', default=512, type=int)\n",
        "parser.add_argument('-batch_size', default=24, type=int)\n",
        "parser.add_argument('-num_epochs', default=4, type=int)\n",
        "parser.add_argument('-learning_rate', default=2e-5, type=float)\n",
        "parser.add_argument('-max_grad_norm', default=1.0, type=float)\n",
        "parser.add_argument('-warm_up_proportion', default=0.1, type=float)\n",
        "parser.add_argument('-gradient_accumulation_step', default=1, type=int)\n",
        "parser.add_argument('-bert_path', default='bert-base-uncased')\n",
        "parser.add_argument('-trunc_mode', default=128, type=str)\n",
        "args = parser.parse_args()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nparser = argparse.ArgumentParser()\\nparser.add_argument('-seed', default=0, type=int)\\nparser.add_argument('-max_seq_length', default=512, type=int)\\nparser.add_argument('-batch_size', default=24, type=int)\\nparser.add_argument('-num_epochs', default=4, type=int)\\nparser.add_argument('-learning_rate', default=2e-5, type=float)\\nparser.add_argument('-max_grad_norm', default=1.0, type=float)\\nparser.add_argument('-warm_up_proportion', default=0.1, type=float)\\nparser.add_argument('-gradient_accumulation_step', default=1, type=int)\\nparser.add_argument('-bert_path', default='bert-base-uncased')\\nparser.add_argument('-trunc_mode', default=128, type=str)\\nargs = parser.parse_args()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbYUajMZ4wJo"
      },
      "source": [
        "args = easydict.EasyDict({\n",
        "        \"seed\": 42,\n",
        "        \"max_seq_length\": 256,\n",
        "        \"batch_size\": 32,\n",
        "        \"num_epochs\": 4,\n",
        "        \"num_labels\":4,\n",
        "        \"learning_rate\":5e-5,\n",
        "        \"adam_epsilon\":1e-8,\n",
        "        \"attention_probs_dropout_prob\" : 0.1,\n",
        "        \"hidden_dropout_prob\" : 0.1,\n",
        "       \n",
        "        \"max_grad_norm\": 1.0,\n",
        "        \"warm_up_proportion\": 0.1,\n",
        "        \"gradient_accumulation_step\": 1,\n",
        "        \"bert_path\": 'bert-base-uncased',\n",
        "        \"trunc_mode\": 128\n",
        "         \n",
        "})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "Nf2vtX10omeO",
        "outputId": "49476b4c-b28e-4435-a47e-3a89cdcc7b7e"
      },
      "source": [
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "train_data = pd.read_csv(DATA_TRAIN_PATH ,  nrows = 3000, delimiter=',', header=None, names=['label', 'title', 'description'], encoding='utf8')\n",
        "#test_data = pd.read_csv(\"/content/drive/MyDrive/yelp_review_full_csv/test.csv\",  nrows = 3000, delimiter=',', header=None, names=['index', 'sentence'])\n",
        "\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(train_data.shape[0]))\n",
        "#print('Number of test sentences: {:,}\\n'.format(test_data.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "#train_data.head()\n",
        "train_data.head()\n",
        "#df.sample(10)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 3,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                        description\n",
              "0      3  ...  Reuters - Short-sellers, Wall Street's dwindli...\n",
              "1      3  ...  Reuters - Private investment firm Carlyle Grou...\n",
              "2      3  ...  Reuters - Soaring crude prices plus worries\\ab...\n",
              "3      3  ...  Reuters - Authorities have halted oil export\\f...\n",
              "4      3  ...  AFP - Tearaway world oil prices, toppling reco...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C3XHkYXRlxb",
        "outputId": "7ccc1941-3018-4a30-9849-ba30f799fd22"
      },
      "source": [
        "train_data.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label  title                                                                                       description                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "4      palmOne announces SD wi-fi card for Tungsten T3 and Zire 72                                 palmOne, Inc. is at last bringing a SD wi-fi solution for a couple of its handheld models. To date, palmOne #39;s Wi-Fi option was the Tungsten C, which comes with built-in wireless, incorporates a keyboard and a 320 x 320 transflective TFT display. palmOne ...                                                                                                                                                                               1\n",
              "2      Lightning Reacquire Prospal From Ducks (AP)                                                 AP - Vaclav Prospal is returning to the Stanley Cup champion Tampa Bay Lightning and will likely take the spot of forward Cory Stillman, who replaced him a year ago.                                                                                                                                                                                                                                                                               1\n",
              "       Many similarities, differences between #39;04 US basketball and #39;80 Soviet hockey teams  This was no miracle, but you could not tell by the amount of elation surrounding the Dream Team #39;s trip to the woodshed Sunday.                                                                                                                                                                                                                                                                                                                  1\n",
              "       Manning Gets Early Go-Ahead to Start                                                        Eli Manning, the No. 1 pick in this year's N.F.L. draft, will make his first professional start on Thursday when the Giants take on the Carolina Panthers.                                                                                                                                                                                                                                                                                          1\n",
              "                                                                                                   Eli Manning, the No. 1 pick in this year's N.F.L. draft, will make his first professional start on Thursday when the Giants take on Carolina.                                                                                                                                                                                                                                                                                                       1\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ..\n",
              "3      Wall Street to Open Little Changed                                                           NEW YORK (Reuters) - Wall Street is seen opening little  changed on Monday as crude prices remain high, but insurers may  dip on worries about their potential liabilities after a  hurricane struck Florida on Friday.                                                                                                                                                                                                                            1\n",
              "       Wall Street takes heart from positive economic reports                                      A NEW record high for oil took some of the shine off Wall Street trade yesterday. An upbeat picture of inflation and good housing data boosted the mood early on and strong earnings from several retailers, led by Home Depot, also helped to keep the major ...                                                                                                                                                                                   1\n",
              "       Wall Street closes higher, but record oil prices cap day #39;s gains                        NEW YORK : Wall Street shares closed higher on Tuesday, but record oil prices capped the day #39;s gains amid concerns over a multi-billion-dollar tax bill facing Russian oil giant Yukos.                                                                                                                                                                                                                                                         1\n",
              "       Wall Street Set to Open Down (Reuters)                                                      Reuters - U.S. shares were expected to open lower\\on Wednesday after crude oil pushed to a fresh high overnight,\\while Web search engine Google Inc. dented sentiment as it\\slashed the price range on its initial public offering.\\In a statement posted on its IPO Web site, Google said it had\\cut the range on its IPO to  #36;85- #36;95 per share from  #36;108- #36;135\\previously, a 26 percent reduction at the mid-point of the\\range.    1\n",
              "1      'Afghanistan needs security help'                                                           UN Secretary-General Kofi Annan says Afghanistan needs help with security to ensure its presidential elections are successful.                                                                                                                                                                                                                                                                                                                      1\n",
              "Length: 3000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbj9mC5XU85F"
      },
      "source": [
        "train_data['sentence'] = train_data['title']+train_data['description']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fesBrQTZNqF",
        "outputId": "3ef9dafe-8137-499c-fd3d-6aa0402cf8d2"
      },
      "source": [
        "train_data['label'].unique()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 4, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0-PkA-zlpgx"
      },
      "source": [
        "#RuntimeError: CUDA error: device-side assert triggered \n",
        "#Loss item RuntimeError CUDA error: device-side assert triggered 나서 레이블 시작을 1에서 0으로 바꿈\n",
        "#train_data['label'] = (train_data['label'] -1 )\n",
        "# the class labels to start at 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywgx7VW7ZdTf",
        "outputId": "178fbf23-becc-4432-b20c-eef69a86b1c3"
      },
      "source": [
        "train_data['label'] = (train_data['label'] -1 )\n",
        "train_data['label'].unique()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Xwa4LaoY4dSJ",
        "outputId": "206de659-8a4d-40dd-fa33-71f66199a8dd"
      },
      "source": [
        "'''\n",
        "train_data = train_data.sampleby('label',\n",
        "                                 frac={'1':0.2,\n",
        "                                       '2':0.2,\n",
        "                                       '3':0.2,\n",
        "                                       '4':0.2,\n",
        "                                       '5':0.2},\n",
        "                                 seed=1234)\n",
        "train_data.groupby('label').count().orderby('label').show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntrain_data = train_data.sampleby('label',\\n                                 frac={'1':0.2,\\n                                       '2':0.2,\\n                                       '3':0.2,\\n                                       '4':0.2,\\n                                       '5':0.2},\\n                                 seed=1234)\\ntrain_data.groupby('label').count().orderby('label').show()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OmEQdZOqygD",
        "outputId": "1951b082-7a50-4ab8-a01c-9406662c3c17"
      },
      "source": [
        "sentences = train_data.sentence.values\n",
        "labels = train_data.label.values\n",
        "\n",
        "sentences"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Wall St. Bears Claw Back Into the Black (Reuters)Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
              "       'Carlyle Looks Toward Commercial Aerospace (Reuters)Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.',\n",
              "       \"Oil and Economy Cloud Stocks' Outlook (Reuters)Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\",\n",
              "       ...,\n",
              "       'Pacers #39; Foster Activated From Injured ListIndianapolis, IN -- Indiana Pacers center Jeff Foster was activated from the injured list Tuesday. He had missed the first 17 games of the season after undergoing hip surgery in October.',\n",
              "       'Physicists Teleport Photons Across DanubeAustrian researchers have teleported photons, or particles of light, for the first time outside a laboratory using the same technological principles imagined by &lt;I&gt;Star Trek.&lt;/I&gt;',\n",
              "       'British Cave Yields Elaborate Ice-Age ArtA detailed survey of ancient cave carvings at a site first discovered last year in Nottinghamshire, England, reveals the etchings may be some of most elaborate Ice Age art ever found.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "2764bafc96e0422290d61a22f39c5120",
            "0f08d012767c4e5db7ea8f777d208dd6",
            "c92adb33225f4dfb97b9cc1d5039cf43",
            "39144536ccec45e6aa23886e02c34733",
            "95664e5d5c7c4b3fb544ea54b894d6c8",
            "3bd87d2f433d421484011bcdb20ec04c",
            "5e9e9b61ffbf4b87923d47758f5badbd",
            "5805e0c7b7264938b5e673ed6837d00f",
            "6618cb74c4184d57a5eb610b88bc2d35",
            "ca03779df9f640e19b0bef5dcb9539b7",
            "296c4190bd8d47fa94c0691fbd9e35b3",
            "745d55b6119a477a9c8f3a5f8cd31e17",
            "dce9d658cb9e42cda8a1b03f327085ca",
            "ec555c6b092d47e08bf1a7591db9c440",
            "f39d682e1b22451889d737b4d12943e5",
            "766efdbd7ea042778ebed40a5c77c848",
            "529140a8709f416c8962a8758f71ba46",
            "bd012ba9bed4423d8c03a66b66423130",
            "925af190d30c4dae9826ffdb7718e611",
            "2d15821345a04b469075116ab1b06ddb",
            "76980fa5c7914fad8c936240b2e7f3cd",
            "a6a93efd878b40759599f74ddc075de8",
            "c5dbcf4e9bb64101bc1f08da6936c1b3",
            "d6466d76c3464bce8bdc099750e897b6"
          ]
        },
        "id": "9xT36S4FrKq-",
        "outputId": "cb206e01-05c1-4f80-968f-79d8ac9bf3c6"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(args.bert_path, do_lower_case=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2764bafc96e0422290d61a22f39c5120",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6618cb74c4184d57a5eb610b88bc2d35",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "529140a8709f416c8962a8758f71ba46",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IU-QB5nsPaE",
        "outputId": "f381f3d2-9fb9-4e18-bcc3-607557c94ef0"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Wall St. Bears Claw Back Into the Black (Reuters)Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
            "Tokenized:  ['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short', '-', 'sellers', ',', 'wall', 'street', \"'\", 's', 'd', '##wind', '##ling', '\\\\', 'band', 'of', 'ultra', '-', 'cy', '##nic', '##s', ',', 'are', 'seeing', 'green', 'again', '.']\n",
            "Token IDs:  [2813, 2358, 1012, 6468, 15020, 2067, 2046, 1996, 2304, 1006, 26665, 1007, 26665, 1011, 2460, 1011, 19041, 1010, 2813, 2395, 1005, 1055, 1040, 11101, 2989, 1032, 2316, 1997, 11087, 1011, 22330, 8713, 2015, 1010, 2024, 3773, 2665, 2153, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "2SvMaQl7suza",
        "outputId": "556275b3-1617-425f-ae68-561d4fc81a9f"
      },
      "source": [
        "'''\n",
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nmax_len = 0\\n\\n# For every sentence...\\nfor sent in sentences:\\n\\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\\n    input_ids = tokenizer.encode(sent, add_special_tokens=True)\\n\\n    # Update the maximum sentence length.\\n    max_len = max(max_len, len(input_ids))\\n\\nprint('Max sentence length: ', max_len)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbMKyVyVtsuV",
        "outputId": "3b1bc4b7-7125-4ee1-dc36-de600dfdb2c6"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = args.max_seq_length,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Wall St. Bears Claw Back Into the Black (Reuters)Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
            "Token IDs: tensor([  101,  2813,  2358,  1012,  6468, 15020,  2067,  2046,  1996,  2304,\n",
            "         1006, 26665,  1007, 26665,  1011,  2460,  1011, 19041,  1010,  2813,\n",
            "         2395,  1005,  1055,  1040, 11101,  2989,  1032,  2316,  1997, 11087,\n",
            "         1011, 22330,  8713,  2015,  1010,  2024,  3773,  2665,  2153,  1012,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNY-VSFK1koI",
        "outputId": "ed187551-45d7-4ec1-cbca-36f6fa426fdc"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2,700 training samples\n",
            "  300 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqKO6NGY16ut"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = args.batch_size\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = args.batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = args.batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9c98fc1dce344fad80e4525ffbfb48c4",
            "73732e79f03b45a284f3762cfc86ab15",
            "142ee2f5b5c44dc3b3426b0ff5704f80",
            "5a96f1c483fb4d0794ac608af7cd99a6",
            "cfa8ba12162740039c86d82982d049a6",
            "6ef847a3d25840efafeb6ac461c6deab",
            "309f72869d5845948cd180f3f27a739e",
            "5ff523e2b6c94edc8b03b63986a00369",
            "ae9d9b1c158d4b0784dbcfb341592682",
            "ffa55e37819547bd83576240f5e6ebf4",
            "f5a9a1de869c4946b04aa8ceb333b880",
            "4e949fbfa24f4b4b962b48bfe29e3ce9",
            "bf31f9ada3514672916ab5ccb377de0c",
            "6097930e573b4ee1ae99f45587a901c2",
            "457f701a1c414b48bdc8f730339331b0",
            "166d27764fe54402babbd8100653af75"
          ]
        },
        "id": "wWpP5evN6rnL",
        "outputId": "5258a052-5276-4b41-e386-a6677c111602"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    args.bert_path, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = args.num_labels, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    attention_probs_dropout_prob = args.attention_probs_dropout_prob,\n",
        "    hidden_dropout_prob = args.hidden_dropout_prob\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c98fc1dce344fad80e4525ffbfb48c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae9d9b1c158d4b0784dbcfb341592682",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-ElBp_NNfaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862f200d-fec6-4ef7-cc94-43d759a900c6"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                          (10, 768)\n",
            "classifier.bias                                                (10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjW3hB2_wkjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5d3cdc81-a244-489b-e0a7-0a27c7815383"
      },
      "source": [
        " '''\n",
        " # Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters  = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Prepare optimizer and schedule (linear warmup and decay)\\nno_decay = ['bias', 'LayerNorm.weight']\\noptimizer_grouped_parameters  = [\\n   {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\\n   {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\\n   ]\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIClet4jOAW3"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = args.learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = args.adam_epsilon # args.adam_epsilon  - default is 1e-8.\n",
        "                  \n",
        "                )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiQIjC5cOGPm"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = args.num_epochs\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsvM5VCvOIDZ"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErJCZN_COUse"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6II6RuCPOYRA"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBdHQ1cHOcnx",
        "outputId": "9e9d4385-da77-4eca-d1fa-07780fec8a14"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = args.seed\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        \n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        \n",
        "        loss, logits = outputs['loss'], outputs['logits']\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss, logits = outputs['loss'], outputs['logits']\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     85.    Elapsed: 0:00:52.\n",
            "  Batch    80  of     85.    Elapsed: 0:01:50.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation Loss: 0.37\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     85.    Elapsed: 0:00:57.\n",
            "  Batch    80  of     85.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:02:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.34\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     85.    Elapsed: 0:00:58.\n",
            "  Batch    80  of     85.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:02:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     85.    Elapsed: 0:00:57.\n",
            "  Batch    80  of     85.    Elapsed: 0:01:55.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:02:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  Validation Loss: 0.41\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:08:21 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "pVe0VsL-XLc1",
        "outputId": "f0dabb90-3d22-4eca-ae2e-f78e52248ade"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0:01:56</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.22</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0:02:01</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0:02:02</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0:02:01</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.57         0.37           0.89       0:01:56         0:00:05\n",
              "2               0.22         0.34           0.90       0:02:01         0:00:05\n",
              "3               0.10         0.40           0.90       0:02:02         0:00:05\n",
              "4               0.05         0.41           0.91       0:02:01         0:00:05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "MXhfW3hfXYqo",
        "outputId": "7726c185-f287-424a-9ec0-eae09ca5071e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv4GtgQnXppG"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol53dQs4hSTD",
        "outputId": "27c9dc48-9de8-4f4a-a032-f4ae0555a05a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "test_data = pd.read_csv(DATA_TEST_PATH, nrows= 3000, delimiter=',', header=None, names=['label', 'title', 'description'])\n",
        "\n",
        "\n",
        "test_data['sentence'] = test_data['title']+test_data['description']\n",
        "\n",
        "\n",
        "test_data['label'] = (test_data['label'] -1 ) # the class labels to start at 0\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(test_data.shape[0]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 3,000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "7gueaW9mhoy6",
        "outputId": "8a048f24-c04c-4c0a-c5aa-2b79aa38ced9"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>question title</th>\n",
              "      <th>question content</th>\n",
              "      <th>best answer</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Fears for T N pension after talks</td>\n",
              "      <td>Unions representing workers at Turner   Newall...</td>\n",
              "      <td></td>\n",
              "      <td>Fears for T N pension after talksUnions repres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
              "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
              "      <td></td>\n",
              "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
              "      <td>AP - A company founded by a chemistry research...</td>\n",
              "      <td></td>\n",
              "      <td>Ky. Company Wins Grant to Study Peptides (AP)A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
              "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
              "      <td></td>\n",
              "      <td>Prediction Unit Helps Forecast Wildfires (AP)A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
              "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
              "      <td></td>\n",
              "      <td>Calif. Aims to Limit Farm-Related Smog (AP)AP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>1</td>\n",
              "      <td>Jeff Gordon leads contenders at Talladega</td>\n",
              "      <td>Joe Nemechek wasn #39;t surprised to be back a...</td>\n",
              "      <td></td>\n",
              "      <td>Jeff Gordon leads contenders at TalladegaJoe N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>0</td>\n",
              "      <td>Ukraine opposition seeks legal changes</td>\n",
              "      <td>KIEV -- Opposition leader Viktor Yushchenko ye...</td>\n",
              "      <td></td>\n",
              "      <td>Ukraine opposition seeks legal changesKIEV -- ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>0</td>\n",
              "      <td>Pakistan Ups Security, Shi #39;ites Mourn Bomb...</td>\n",
              "      <td>Pakistan beefed up security Saturday as minori...</td>\n",
              "      <td></td>\n",
              "      <td>Pakistan Ups Security, Shi #39;ites Mourn Bomb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>1</td>\n",
              "      <td>Angels One Win From AL West Title (AP)</td>\n",
              "      <td>AP - The Anaheim Angels considered themselves ...</td>\n",
              "      <td></td>\n",
              "      <td>Angels One Win From AL West Title (AP)AP - The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>0</td>\n",
              "      <td>Violent Protests Erupt Again in Haiti</td>\n",
              "      <td>PORT-AU-PRINCE, Haiti Oct. 2, 2004 - Supporter...</td>\n",
              "      <td></td>\n",
              "      <td>Violent Protests Erupt Again in HaitiPORT-AU-P...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  ...                                           sentence\n",
              "0         2  ...  Fears for T N pension after talksUnions repres...\n",
              "1         3  ...  The Race is On: Second Private Team Sets Launc...\n",
              "2         3  ...  Ky. Company Wins Grant to Study Peptides (AP)A...\n",
              "3         3  ...  Prediction Unit Helps Forecast Wildfires (AP)A...\n",
              "4         3  ...  Calif. Aims to Limit Farm-Related Smog (AP)AP ...\n",
              "...     ...  ...                                                ...\n",
              "2995      1  ...  Jeff Gordon leads contenders at TalladegaJoe N...\n",
              "2996      0  ...  Ukraine opposition seeks legal changesKIEV -- ...\n",
              "2997      0  ...  Pakistan Ups Security, Shi #39;ites Mourn Bomb...\n",
              "2998      1  ...  Angels One Win From AL West Title (AP)AP - The...\n",
              "2999      0  ...  Violent Protests Erupt Again in HaitiPORT-AU-P...\n",
              "\n",
              "[3000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNEf_SOBXxy1"
      },
      "source": [
        "\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = test_data.sentence.values\n",
        "labels = test_data.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = args.max_seq_length,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = args.batch_size  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56FBOoS9YeuP"
      },
      "source": [
        "## Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLL4uaKhc7VH",
        "outputId": "c1dbf168-fb6c-4271-d197-5d05f27848f6"
      },
      "source": [
        "\n",
        "t0 = time.time()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "for step, batch in enumerate(prediction_dataloader):\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(prediction_dataloader), elapsed))\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():     \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.90\n",
            "Test took: 0:00:51\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}