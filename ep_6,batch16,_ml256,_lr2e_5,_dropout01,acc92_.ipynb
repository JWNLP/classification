{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ep 6,batch16, ml256,  lr2e-5, dropout01,acc92 .ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JWNLP/classification/blob/main/ep_6%2Cbatch16%2C_ml256%2C_lr2e_5%2C_dropout01%2Cacc92_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ1AiW4am5G0",
        "outputId": "2b85be00-d386-4b93-f981-bbbfef5a6206"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbmwCmOsX36p",
        "outputId": "0fba9a3d-e92c-4a8e-9054-1d426aec08e9"
      },
      "source": [
        "pip install transformers\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1hzzzfMlec-",
        "outputId": "07de942a-493c-4a03-ec8e-a84126222145"
      },
      "source": [
        "pip install matplotlib"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0-PkA-zlpgx"
      },
      "source": [
        "#!pip install ignite"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKXLb7Ot-ogN",
        "outputId": "b1696823-ecb0-4e35-ec81-6acd86d553c7"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVfzNcrBYfAc"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from tqdm import tqdm"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Nf2vtX10omeO",
        "outputId": "ddc76aff-250d-420e-ae04-6ecd8e519e3f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/imbd_csv/imdb_train.csv\", delimiter='\\t', header=None, names=['label', 'sentence'])\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/imbd_csv/imdb_test.csv\", delimiter='\\t', header=None, names=['label', 'sentence'])\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(train_data.shape[0]))\n",
        "print('Number of test sentences: {:,}\\n'.format(test_data.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "#train_data.head()\n",
        "train_data.head()\n",
        "#df.sample(10)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 25,000\n",
            "\n",
            "Number of test sentences: 25,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Well, if you are looking for a great mind cont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I had the privilege of watching Scarface on th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>That's a snippet of choice dialogue delivered ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Predictable, told a thousand times story with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>This is the worst movie ever made. The acting,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           sentence\n",
              "0      1  Well, if you are looking for a great mind cont...\n",
              "1      1  I had the privilege of watching Scarface on th...\n",
              "2      0  That's a snippet of choice dialogue delivered ...\n",
              "3      0  Predictable, told a thousand times story with ...\n",
              "4      0  This is the worst movie ever made. The acting,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OmEQdZOqygD",
        "outputId": "46334763-3f2b-4025-bda8-e7c5692283af"
      },
      "source": [
        "sentences = train_data.sentence.values\n",
        "labels = train_data.label.values\n",
        "\n",
        "sentences\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Well, if you are looking for a great mind control movie, this is it. No movie has had so many gorgeous women under mind control, and naked. Marie Forsa, as the busty Helga, is under just about everytime she falls asleep and a few times when she isn't. One wishes they made more movies like this one.\",\n",
              "       \"I had the privilege of watching Scarface on the big screen with its beautifully restored 35mm print in honor of the 20th anniversary of the films release. It was great to see this on the big screen as so much of it is lost on television sets and the overall largesse of this project cannot be emphasized enough.  Scarface is the remake of a classic rags to riches to the depths of hell story featuring Al Pacino as Cuban drug lord Tony Montana. In this version, Tony comes to America during the Cuban boat people immigration wave in the late 1970s, early 1980s. Tony and his cohorts quickly get green cards by offing a political figure in Tent City and after a brief stay at a Cuban restaurant; Tony is launched on his horrific path to towards total destruction.  Many of the characters in this movie a played in such skilled manner that is so enjoyable to watch I have forgot little of this film over the last twenty years. Robert Loggia as Tony's patron, Frank Lopez is wonderful. His character is flawed by being too trusting, and as Tony quickly figures out, soft. Lopez's right hand, Omar Suarez is portrayed by one of our greatest actors, F. Murray Abraham (Amadeus.) Suarez is the ultimate toady and will do anything for Frank; it is like he does not have a mind of his own. Tony quickly sees this and he constantly battles with Suarez, but really only sees him as a minor problem to get through on his way to the top. The character that always comes back to me as being played so perfectly is Mel Bernstein, the audaciously corrupt Miami Narcotics detective played by Harris Yulin (Training Day.) Mel, without guilt extorts great sums of money form all sides of the drug industry. He plays Tony off of Frank until it catches up with him in a scene that marks the exit from the film of both Frank and Mel. It is priceless to hear Frank asking for Mel to intercede, as Tony is about to kill him only to hear Mel reply, `It's your tree Frank, you're sitting in it.' This is from the man who Frank had been paying for protection! Tony's rise is meteoric and is only matched in speed and intensity by his quick crash and burn. After offing Frank and taking his wife and business Tony's greed takes over and he never can seem to get enough. As Tony plunges deeper into the world of drugs, greed and the inability to trust he eventually kills his best friend and his sister who had fallen in love and married. This all sets up the ending in which Tony's compound is stormed by an army from his supplier who feels betrayed because Tony would not go through with a political assassination that was ordered. This all stems form a compassionate moment when Tony refused to be an accomplice in a murder that would have involved the victim's wife and children. All in all this is a great depiction of 1980s excess and cocaine culture. DePalma does a nice job of holding it all together in one of the fastest moving three hour movies around. The violence is extremely graphic and contains a few scenes that will be forever etched on any viewers mind, particularly the gruesome chainsaw seen, the two point blank shots to the head and the entire bloody melee that ends the movie. This is a highly recommended stylistically done film that is not for the squeamish, or for those who need upbeat endings and potential sequels; DePalma let it all fly right here.\",\n",
              "       'That\\'s a snippet of choice dialogue delivered by the evil, ballbusting lady assistant of a famous scientist to her prim maid just before she lures three incredibly dumb college girls to a mansion for behavior modification experiments. Meanwhile, at the local bar, people drink and dance to lame 80s rock songs. A biker punk has sex with a cycle slut on a pinball table in front of a crowd of people, then tries to rape the scientist\\'s virginal daughter Jessica (Debra Hunter), who is in love with another biker (Dale Midkiff, from PET SEMATARY), who, in turn, is in cohorts with the assistant! Back at the house, the sorority bimbos swim, shower, change clothes and have sex with men from the bar. A small silver ball (part of the experiment) flies into victims mouths and turns them into drooling, killer zombies! If that isn\\'t enough to entertain you, there\\'s a hilarious theme song (\"Nightmare Fantasy\"), roller skating, some serious daisy dukes and a psychic hand puppet (!?) that warns \"DANGER! DANGER!\" just like the LOST IN SPACE robot and recommends hitchhiking as one of the best ways to pick up men! This filmed-in-Florida mess is so mind-numbingly awful that multiple viewings are recommended to soak it all in. And, hey isn\\'t that NYPD Blue\\'s Detective Jill Kirkendall turned CNN newscaster Andrea Thompson as one of oft-nude bimbos? Sure is! Supposedly this was started in 1982 and new footage was added later for the video release in 1985. Score: 1 out of 10 (and I mean that in a good way!)',\n",
              "       ...,\n",
              "       'Medellin is a fabulous place to live, work, and study. I\\'ve been there twice, and never did I hear anything about guerrilla activities, paramilitaries taking tourists hostage, or anything of the sort. There are \"invisible police,\" but it is *not* a Big Brother system. There are just enough police so that they are visible in everyday life, but they do not hassle someone without good reasons. La Sierra is an interesting documentary in that the youths it depicts in the movie essentially become its characters. The directors of the movie carefully carve out plot lines among the daily actions of the inhabitants of La Sierra, and when a \"character\" dies, there is genuine pathos. It is difficult to imagine, however, that the three youths are all members of the Bloque Metro, a gang that used to terrorize La Sierra before the Colombian government began to restructure the country. La Sierra is not an accurate depiction of life in Colombia; there are, of course, things to be wary of such as petty crime, but when one considers pickpocketing happens in \"modern\" cities such as London, New York, or Tokyo, Colombia doesn\\'t seem that different after all. Colombians are eagerly awaiting their chance to show to the world that the once war-torn country is now prospering more than ever.',\n",
              "       'The first time I had the window of opportunity to see this all but forgotten classic was back in the early 1980\\'s,at one of our art houses as a revival. As I watched this fever dream of an exercise in 1930\\'s sexuality, I thought YOWZA! They got away with murder in Europe back in the day. Unfortunately, this film was heavily cut in it\\'s original U.S. release by the blue nosed Hayes Office (the staunch government censorship board,started by the \"holier than thou\" Bible thumper, Will Hayes...a former Post Office official,if you can believe that),due to it\\'s overall theme of human sexuality (Heaven\\'s forbid humans actually had sex in the 1930\\'s). The plot of Ecstasy concerns a young woman (played by Hedy Lamarr)who marries a much older man,and later regrets it. She (Lamarr)meets a handsome younger man & has an affair with him, resulting in a divorce from previous husband (another no no in Hollywood movies back then---Divorce!). Despite the fact that the film was produced in 1933, it was probably the director\\'s first time working in the sound format (i.e. the film seems to possess techniques that were used mostly in silent films---i.e. 1920\\'s expressionism\\'s). It\\'s still worth searching out for a window into early European talking pictures,along with Luis Bunuels L\\'Age Dor (1930),and Karl Gustav Dryer\\'s \\'Vampyre\\' (1931). Not rated,but contains that infamous nude swimming scene & some thinly veiled sexual references, which would fare little more than a PG-13 by today\\'s standards (but would have easily landed the dreaded \\'X\\',back in the 30\\'s,if it existed then)',\n",
              "       \"Smallville episode Justice is the best episode of Smallville ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! It's my favorite episode of Smallville! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xT36S4FrKq-",
        "outputId": "00617f04-ed31-41e7-b5b0-45ebdcf614ab"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IU-QB5nsPaE",
        "outputId": "3a002341-9b74-4cbe-a027-06e89f5e51b8"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Well, if you are looking for a great mind control movie, this is it. No movie has had so many gorgeous women under mind control, and naked. Marie Forsa, as the busty Helga, is under just about everytime she falls asleep and a few times when she isn't. One wishes they made more movies like this one.\n",
            "Tokenized:  ['well', ',', 'if', 'you', 'are', 'looking', 'for', 'a', 'great', 'mind', 'control', 'movie', ',', 'this', 'is', 'it', '.', 'no', 'movie', 'has', 'had', 'so', 'many', 'gorgeous', 'women', 'under', 'mind', 'control', ',', 'and', 'naked', '.', 'marie', 'for', '##sa', ',', 'as', 'the', 'bust', '##y', 'he', '##lga', ',', 'is', 'under', 'just', 'about', 'every', '##time', 'she', 'falls', 'asleep', 'and', 'a', 'few', 'times', 'when', 'she', 'isn', \"'\", 't', '.', 'one', 'wishes', 'they', 'made', 'more', 'movies', 'like', 'this', 'one', '.']\n",
            "Token IDs:  [2092, 1010, 2065, 2017, 2024, 2559, 2005, 1037, 2307, 2568, 2491, 3185, 1010, 2023, 2003, 2009, 1012, 2053, 3185, 2038, 2018, 2061, 2116, 9882, 2308, 2104, 2568, 2491, 1010, 1998, 6248, 1012, 5032, 2005, 3736, 1010, 2004, 1996, 13950, 2100, 2002, 27887, 1010, 2003, 2104, 2074, 2055, 2296, 7292, 2016, 4212, 6680, 1998, 1037, 2261, 2335, 2043, 2016, 3475, 1005, 1056, 1012, 2028, 8996, 2027, 2081, 2062, 5691, 2066, 2023, 2028, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SvMaQl7suza",
        "outputId": "09964ef3-bc99-4953-9aa8-27f3e82f82ab"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  3047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbMKyVyVtsuV",
        "outputId": "2ec1e70d-ac88-45a8-e975-3975aed38baf"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Well, if you are looking for a great mind control movie, this is it. No movie has had so many gorgeous women under mind control, and naked. Marie Forsa, as the busty Helga, is under just about everytime she falls asleep and a few times when she isn't. One wishes they made more movies like this one.\n",
            "Token IDs: tensor([  101,  2092,  1010,  2065,  2017,  2024,  2559,  2005,  1037,  2307,\n",
            "         2568,  2491,  3185,  1010,  2023,  2003,  2009,  1012,  2053,  3185,\n",
            "         2038,  2018,  2061,  2116,  9882,  2308,  2104,  2568,  2491,  1010,\n",
            "         1998,  6248,  1012,  5032,  2005,  3736,  1010,  2004,  1996, 13950,\n",
            "         2100,  2002, 27887,  1010,  2003,  2104,  2074,  2055,  2296,  7292,\n",
            "         2016,  4212,  6680,  1998,  1037,  2261,  2335,  2043,  2016,  3475,\n",
            "         1005,  1056,  1012,  2028,  8996,  2027,  2081,  2062,  5691,  2066,\n",
            "         2023,  2028,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNY-VSFK1koI",
        "outputId": "59cd6163-ba74-4d0d-a5b6-ac8f086f907f"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22,500 training samples\n",
            "2,500 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqKO6NGY16ut"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWpP5evN6rnL",
        "outputId": "9b71bfbd-5762-4741-afe2-8b64e88d1c32"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    attention_probs_dropout_prob = 0.3,\n",
        "    hidden_dropout_prob = 0.3\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-ElBp_NNfaX",
        "outputId": "e43aed4a-5e82-45ae-fb88-dc4e39a7483f"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjW3hB2_wkjB"
      },
      "source": [
        " # Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIClet4jOAW3"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                  \n",
        "                )"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiQIjC5cOGPm"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 6\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsvM5VCvOIDZ"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErJCZN_COUse"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6II6RuCPOYRA"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBdHQ1cHOcnx",
        "outputId": "4973f2af-5c39-4ab1-ba1e-95257294c082"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        \n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        \n",
        "        loss, logits = outputs['loss'], outputs['logits']\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss, logits = outputs['loss'], outputs['logits']\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:01:03.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:01:34.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:02:05.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:02:36.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:03:07.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:03:39.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:04:10.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:04:41.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:05:12.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:05:44.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:06:15.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:06:46.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:07:17.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:07:49.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:08:20.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:08:51.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:09:23.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:09:54.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:10:25.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:10:57.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:11:28.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:11:59.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:12:30.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:13:02.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:13:33.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:14:04.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:14:35.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:15:07.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:15:38.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:16:09.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:16:41.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:17:12.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:17:43.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:18:14.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:18:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.26\n",
            "  Validation took: 0:00:42\n",
            "\n",
            "======== Epoch 2 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:01:03.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:01:34.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:02:05.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:02:36.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:03:07.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:03:38.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:04:10.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:04:41.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:05:12.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:05:44.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:06:15.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:06:46.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:07:17.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:07:48.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:08:20.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:08:51.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:09:22.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:09:53.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:10:24.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:10:56.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:11:27.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:11:58.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:12:29.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:13:00.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:13:32.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:14:03.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:14:34.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:15:05.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:15:37.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:16:08.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:16:39.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:17:10.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:17:41.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:18:13.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:18:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.27\n",
            "  Validation took: 0:00:42\n",
            "\n",
            "======== Epoch 3 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:01:03.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:01:34.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:02:05.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:02:36.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:03:07.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:03:39.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:04:10.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:04:41.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:05:12.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:05:43.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:06:14.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:06:46.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:07:17.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:07:48.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:08:19.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:08:50.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:09:21.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:09:53.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:10:24.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:10:55.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:11:26.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:11:57.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:12:29.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:13:00.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:13:31.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:14:02.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:14:33.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:15:05.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:15:36.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:16:07.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:16:38.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:17:09.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:17:40.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:18:12.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:18:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:42\n",
            "\n",
            "======== Epoch 4 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:01:02.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:01:33.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:02:05.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:02:36.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:03:07.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:03:38.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:04:09.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:04:40.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:05:11.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:05:43.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:06:14.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:06:45.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:07:16.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:07:47.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:08:18.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:08:49.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:09:21.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:09:52.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:10:23.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:10:54.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:11:25.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:11:57.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:12:28.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:12:59.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:13:30.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:14:01.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:14:32.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:15:03.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:15:34.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:16:05.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:16:36.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:17:07.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:17:38.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:18:10.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:18:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.49\n",
            "  Validation took: 0:00:42\n",
            "\n",
            "======== Epoch 5 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:01:02.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:01:33.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:02:04.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:02:36.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:03:07.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:03:38.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:04:09.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:04:40.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:05:11.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:05:42.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:06:13.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:06:44.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:07:15.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:07:46.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:08:17.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:08:48.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:09:19.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:09:51.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:10:22.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:10:53.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:11:24.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:11:55.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:12:26.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:12:57.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:13:28.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:13:59.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:14:30.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:15:01.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:15:33.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:16:04.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:16:35.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:17:06.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:17:37.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:18:08.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:18:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.50\n",
            "  Validation took: 0:00:42\n",
            "\n",
            "======== Epoch 6 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of  1,407.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  1,407.    Elapsed: 0:01:02.\n",
            "  Batch   120  of  1,407.    Elapsed: 0:01:33.\n",
            "  Batch   160  of  1,407.    Elapsed: 0:02:05.\n",
            "  Batch   200  of  1,407.    Elapsed: 0:02:36.\n",
            "  Batch   240  of  1,407.    Elapsed: 0:03:07.\n",
            "  Batch   280  of  1,407.    Elapsed: 0:03:38.\n",
            "  Batch   320  of  1,407.    Elapsed: 0:04:09.\n",
            "  Batch   360  of  1,407.    Elapsed: 0:04:41.\n",
            "  Batch   400  of  1,407.    Elapsed: 0:05:12.\n",
            "  Batch   440  of  1,407.    Elapsed: 0:05:43.\n",
            "  Batch   480  of  1,407.    Elapsed: 0:06:15.\n",
            "  Batch   520  of  1,407.    Elapsed: 0:06:46.\n",
            "  Batch   560  of  1,407.    Elapsed: 0:07:17.\n",
            "  Batch   600  of  1,407.    Elapsed: 0:07:48.\n",
            "  Batch   640  of  1,407.    Elapsed: 0:08:20.\n",
            "  Batch   680  of  1,407.    Elapsed: 0:08:51.\n",
            "  Batch   720  of  1,407.    Elapsed: 0:09:22.\n",
            "  Batch   760  of  1,407.    Elapsed: 0:09:54.\n",
            "  Batch   800  of  1,407.    Elapsed: 0:10:25.\n",
            "  Batch   840  of  1,407.    Elapsed: 0:10:56.\n",
            "  Batch   880  of  1,407.    Elapsed: 0:11:28.\n",
            "  Batch   920  of  1,407.    Elapsed: 0:11:59.\n",
            "  Batch   960  of  1,407.    Elapsed: 0:12:30.\n",
            "  Batch 1,000  of  1,407.    Elapsed: 0:13:02.\n",
            "  Batch 1,040  of  1,407.    Elapsed: 0:13:33.\n",
            "  Batch 1,080  of  1,407.    Elapsed: 0:14:04.\n",
            "  Batch 1,120  of  1,407.    Elapsed: 0:14:36.\n",
            "  Batch 1,160  of  1,407.    Elapsed: 0:15:07.\n",
            "  Batch 1,200  of  1,407.    Elapsed: 0:15:38.\n",
            "  Batch 1,240  of  1,407.    Elapsed: 0:16:09.\n",
            "  Batch 1,280  of  1,407.    Elapsed: 0:16:41.\n",
            "  Batch 1,320  of  1,407.    Elapsed: 0:17:12.\n",
            "  Batch 1,360  of  1,407.    Elapsed: 0:17:43.\n",
            "  Batch 1,400  of  1,407.    Elapsed: 0:18:14.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:18:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.53\n",
            "  Validation took: 0:00:42\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:53:53 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "pVe0VsL-XLc1",
        "outputId": "6d81d6e3-2a0d-4bde-b5a6-88a6a7d8cf15"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:18:19</td>\n",
              "      <td>0:00:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.16</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:18:17</td>\n",
              "      <td>0:00:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.09</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:18:17</td>\n",
              "      <td>0:00:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:18:14</td>\n",
              "      <td>0:00:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:18:13</td>\n",
              "      <td>0:00:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:18:19</td>\n",
              "      <td>0:00:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.28         0.26           0.92       0:18:19         0:00:42\n",
              "2               0.16         0.27           0.92       0:18:17         0:00:42\n",
              "3               0.09         0.40           0.92       0:18:17         0:00:42\n",
              "4               0.04         0.49           0.92       0:18:14         0:00:42\n",
              "5               0.02         0.50           0.92       0:18:13         0:00:42\n",
              "6               0.01         0.53           0.92       0:18:19         0:00:42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "MXhfW3hfXYqo",
        "outputId": "d217d9c8-f167-49aa-f88f-8c3e23bd7214"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv4GtgQnXppG"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNEf_SOBXxy1",
        "outputId": "d95127ea-e1a7-423d-a9ea-f11758a215bc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/imbd_csv/imdb_test.csv\", delimiter='\\t', header=None, names=['label', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(test_data.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = test_data.sentence.values\n",
        "labels = test_data.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 25,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56FBOoS9YeuP"
      },
      "source": [
        "## Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLL4uaKhc7VH",
        "outputId": "47550479-f346-4526-d057-860969a38738"
      },
      "source": [
        "\n",
        "t0 = time.time()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "for step, batch in enumerate(prediction_dataloader):\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(prediction_dataloader), elapsed))\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():     \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,563.    Elapsed: 0:00:24.\n",
            "  Batch   200  of  1,563.    Elapsed: 0:00:49.\n",
            "  Batch   300  of  1,563.    Elapsed: 0:01:15.\n",
            "  Batch   400  of  1,563.    Elapsed: 0:01:42.\n",
            "  Batch   500  of  1,563.    Elapsed: 0:02:08.\n",
            "  Batch   600  of  1,563.    Elapsed: 0:02:35.\n",
            "  Batch   700  of  1,563.    Elapsed: 0:03:02.\n",
            "  Batch   800  of  1,563.    Elapsed: 0:03:29.\n",
            "  Batch   900  of  1,563.    Elapsed: 0:03:57.\n",
            "  Batch 1,000  of  1,563.    Elapsed: 0:04:24.\n",
            "  Batch 1,100  of  1,563.    Elapsed: 0:04:51.\n",
            "  Batch 1,200  of  1,563.    Elapsed: 0:05:18.\n",
            "  Batch 1,300  of  1,563.    Elapsed: 0:05:46.\n",
            "  Batch 1,400  of  1,563.    Elapsed: 0:06:13.\n",
            "  Batch 1,500  of  1,563.    Elapsed: 0:06:40.\n",
            "\n",
            "Accuracy: 0.92\n",
            "Test took: 0:06:57\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}